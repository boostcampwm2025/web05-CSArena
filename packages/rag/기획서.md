# (기획서) HyperCLOVA X Structured RAG 파이프라인

## 1. 프로젝트 개요

- **프로젝트명:** Backend-Interview-RAG-Pipeline
- **목적:** 기 구축된 PostgreSQL DB(`categories`, `document_embeddings`)와 `langchain-naver`를 연동하여, HyDE 기반의 검색과 Structured Output 생성을 통해 **"검증된 백엔드 면접 질문"**을 자동 생성함.
- **핵심 기법:**

1. **HyDE (Hypothetical Document Embedding):** 단순 키워드 매칭이 아닌, '의미론적 검색'을 위한 최적의 영문 쿼리 생성.
2. **Structured Output:** HyperCLOVA X의 출력을 JSON으로 강제하여 데이터 파이프라인의 안정성 확보.
3. **RAGAS Evaluation:** 생성된 질문-답변의 품질을 수치적으로 검증.

## 2. 시스템 아키텍처 (Workflow)

1. **Trigger:** DB에서 문제 출제 대상(Leaf Node)과 카테고리 경로(Path) 조회.
2. **HyDE Generation:** HCX-007이 검색 최적화 쿼리(영문) 생성.
3. **Embedding:** Clova Embedding v2로 벡터화.
4. **Retrieval:** 기존 DB(`document_embeddings`)에서 유사도 Top-5 청크 검색.
5. **Generation:** HCX-007(JSON Mode)이 청크 기반 질문 10개 생성.
6. **Evaluation:** RAGAS를 통한 품질 검증.
7. **Storage:** 최종 결과 JSON 저장.

## 3. 기술 스택

- **Core:** Python 3.10+, `langchain-naver`, `RAGAS`
- **Database:** PostgreSQL 18 (Existing), `pgvector`
- **AI Models (Naver Cloud):**
- Generation: **HCX-007**
- Embedding: **clir-emb-dolphin** (1024 Dimension)

## 4. 데이터베이스 스키마 (Reference)

**※ 파이프라인은 아래의 기 구축된 테이블을 참조하여 동작합니다.**

### 4.1. 카테고리 테이블 (`categories`)

```sql
CREATE TABLE categories (
  id BIGSERIAL PRIMARY KEY,
  category_key VARCHAR(255) NOT NULL UNIQUE,
  name VARCHAR(255) NOT NULL,
  depth INT NOT NULL,
  parent_id BIGINT NULL,
  is_leaf BOOLEAN NOT NULL DEFAULT FALSE,
  status VARCHAR(20) NOT NULL DEFAULT 'active',
  created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
  CONSTRAINT fk_category_parent FOREIGN KEY (parent_id) REFERENCES categories(id)
);

```

### 4.2. 지식 임베딩 테이블 (`document_embeddings`)

```sql
CREATE TABLE document_embeddings (
  id SERIAL4 PRIMARY KEY,
  content TEXT NOT NULL,       -- 지식 본문
  category VARCHAR(255),       -- 보조 카테고리 정보
  embedding public.vector,     -- Clova v2 (1024차원)
  tsvector tsvector,           -- 전문 검색용 (Optional)
  metadata JSONB,              -- 출처 등 메타데이터
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

```

## 5. 파이프라인 상세 로직 (Step-by-Step)

### Step 1: Category & Path Loader

- **Logic:** `categories` 테이블에서 `is_leaf = TRUE`인 항목을 조회합니다.
- **Data Preparation:** 단순히 주제명(`name`)만 가져오는 것이 아니라, 재귀 쿼리(Recursive Query) 등을 통해 **전체 경로(Category Path)**를 구성합니다.
- _Example Input:_
- Topic: "TCP 3-way Handshake"
- Path: "Computer Network > Transport Layer > TCP Connection Management"

### Step 2: HyDE Generator (검색 최적화 쿼리 생성)

- **Model:** HCX-007 (General Mode, `temperature=0.3`)
- **System Prompt (Persona & Rules):**
  > 당신은 IT 기술 문서 검색 전문가입니다.
  > 주어진 주제에 대해 의미론적 검색(semantic search)에 최적화된 쿼리를 생성합니다.
  > **규칙:**

> 1. 주제의 핵심 개념을 명확하게 설명하는 문장만을 작성합니다.
> 2. 주제가 가장 중요하므로 주제 관련 설명을 먼저 작성합니다.
> 3. 한국 IT 기술 면접에서 자주 출제되는 관점을 반영합니다.
> 4. 반드시 영어(English)로 작성합니다.
> 5. 100단어 이내로 작성합니다.

- **User Input:**

```text
Topic: {topic_name}
Category Path: {category_path}

```

- **Output:** `hypothetical_query` (검색용 영문 텍스트)

### Step 3: Retrieval (Vector Search)

- **Embedding:** `ClovaXEmbeddings` (v2)를 사용하여 `hypothetical_query`를 벡터화 (`query_vector`).
- **Query Logic:**
- `document_embeddings` 테이블 대상.
- 필터링 조건 없이, 오직 **Cosine Distance** (`<=>`) 기준으로 정렬.
- **LIMIT 5** (상위 5개 청크 추출).

- **Result:** `[ {id: 101, content: "..."}, {id: 204, content: "..."}, ... ]`

### Step 4: Structured Question Generation (질문 생성)

- **Model:** HCX-007 (Structured Output Mode)
- LangChain의 `.bind(responseFormat=...)` 활용.
- `thinking` 파라미터 비활성화 (충돌 방지).

- **Schema Enforcement (JSON):**
- `text` (질문), `model_answer` (답변), `source_chunk_ids` (참조 ID 배열) 필드 필수 포함.

- **Prompt Strategy:**

```text
[Context]
{retrieved_chunks_with_ids}

[Instruction]
위 Context를 기반으로 백엔드 신입 개발자 면접 질문 10개를 생성하시오.
반드시 지정된 JSON 스키마에 맞춰 출력해야 하며, 각 질문이 근거로 한 Context의 ID를 'source_chunk_ids'에 정확히 명시하시오.

```

### Step 5: RAGAS Evaluation (품질 검증)

- **Tool:** RAGAS Framework
- **Inputs:**
- `questions`: 생성된 질문 리스트.
- `contexts`: 질문별 `source_chunk_ids`에 해당하는 원본 청크 텍스트.
- `ground_truths`: (Optional - LLM 생성 답안 평가 시 생략 가능하나, 정확한 평가를 위해 `model_answer`를 활용).

- **Metrics:**
- `Faithfulness`: 답변이 청크 내용에 기반하는가? (할루시네이션 체크)
- `Answer Relevance`: 질문의 의도에 적합한가?

### Step 6: Result Storage

- **Action:** 최종 결과를 JSON 파일로 저장 (로컬 또는 S3).
- **Format:**

```json
{
  "category_info": {
    "id": 123,
    "name": "TCP 3-way Handshake",
    "path": "Network > Transport..."
  },
  "generated_questions": [
    {
      "question": "...",
      "answer": "...",
      "source_ids": [101, 204],
      "ragas_score": 0.95
    },
    ...
  ]
}

```

## 6. 구현 가이드 (LangChain Integration)

- **패키지:** `langchain-naver` 사용 (공식 지원).
- **API Key:** `CLOVASTUDIO_API_KEY` 환경 변수 관리.
- **Structured Output:**
- `ChatClovaX` 인스턴스 생성 시 `model='HCX-007'` 지정.
- 실행 시 `.bind(responseFormat={"type": "json", "schema": ...})` 메서드를 통해 JSON 출력을 강제.

- **Embedding:**
- `ClovaXEmbeddings` 인스턴스 생성 시 `model='clir-emb-dolphin'` 지정 (1024차원 확인).
